#!/usr/bin/env python3
"""
LightGlue Feature Matching Script for PoSDK
è°ƒç”¨LightGlueæ·±åº¦å­¦ä¹ åŒ¹é…å™¨è¿›è¡Œç‰¹å¾åŒ¹é…
"""

import argparse
import sys
import os
import subprocess
from pathlib import Path

# ç¯å¢ƒæ£€æŸ¥å’Œé…ç½®
def check_and_setup_environment():
    """æ£€æŸ¥å¹¶é…ç½®LightGlueç¯å¢ƒ"""
    script_dir = Path(__file__).parent
    
    # 1. é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰drawerç¯å¢ƒå¯ç”¨
    drawer_env_paths = [
        # ä»output/plugins/methods/å‡ºå‘æŸ¥æ‰¾drawerç¯å¢ƒ
        script_dir / "../../po_core/drawer/conda_env/bin/python",
        script_dir / "../../../po_core/drawer/conda_env/bin/python", 
        script_dir / "../../../../po_core/drawer/conda_env/bin/python",
        script_dir / "../../../../../po_core/drawer/conda_env/bin/python",
        
        # ç»å¯¹è·¯å¾„å°è¯•ï¼ˆå¦‚æœç›¸å¯¹è·¯å¾„ä¸å·¥ä½œï¼‰
        Path("/Users/caiqi/Documents/PoMVG/po_core/drawer/conda_env/bin/python"),
    ]
    
    for env_path in drawer_env_paths:
        if env_path.exists():
            print(f"Found drawer environment: {env_path}")
            # æµ‹è¯•ç¯å¢ƒæ˜¯å¦åŒ…å«åŸºç¡€åŒ…
            try:
                result = subprocess.run([str(env_path), "-c", "import numpy, torch, cv2"], 
                                      capture_output=True, timeout=10)
                if result.returncode == 0:
                    print("Drawer environment contains required packages")
                    # æ›´æ–°ç³»ç»Ÿè·¯å¾„
                    env_bin_dir = str(env_path.parent)
                    os.environ['PATH'] = f"{env_bin_dir}:{os.environ.get('PATH', '')}"
                    
                    # é‡æ–°å°è¯•å¯¼å…¥
                    try:
                        import sys
                        sys.path.insert(0, env_bin_dir)
                        import numpy as np
                        import torch
                        import cv2
                        print("Successfully using drawer environment")
                        return True
                    except ImportError:
                        continue
            except (subprocess.TimeoutExpired, Exception):
                continue
    
    # 2. å°è¯•å¯¼å…¥å¿…è¦çš„åŒ…ï¼ˆç³»ç»Ÿç¯å¢ƒï¼‰
    try:
        import numpy as np
        import torch
        import cv2
        print("Basic packages available in system environment")
        return True
    except ImportError as e:
        print(f"Missing dependencies in system environment: {e}")
        
        # 3. æä¾›å®‰è£…æŒ‡å¯¼
        print("Please install dependencies using one of these methods:")
        print("Method 1 - pip install:")
        print("  pip install torch torchvision numpy opencv-python")
        print("")
        print("Method 2 - conda install:")
        print("  conda install pytorch torchvision numpy opencv -c pytorch")
        print("")
        print("Method 3 - use drawer environment:")
        print("  cd po_core/drawer && bash configure_drawer_env.sh")
        return False

# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—å‰å…ˆæ£€æŸ¥ç¯å¢ƒ
if not check_and_setup_environment():
    print("ERROR: Failed to setup LightGlue environment")
    print("Please manually install dependencies:")
    print("  pip install torch torchvision numpy opencv-python")
    sys.exit(1)

# ç°åœ¨å®‰å…¨åœ°å¯¼å…¥æ‰€éœ€æ¨¡å—
import numpy as np
import torch
import cv2

# æ·»åŠ LightGlueç›®å½•åˆ°Pythonè·¯å¾„
script_dir = Path(__file__).parent
print(f"LightGlue script running from: {script_dir}")
print(f"Current working directory: {Path.cwd()}")

# æŸ¥æ‰¾LightGlueå®‰è£…ä½ç½®
lightglue_search_paths = [
    # ç»å¯¹è·¯å¾„ï¼ˆæœ€å¯é ï¼‰
    Path("/Users/caiqi/Documents/PoMVG/src/dependencies/LightGlue-main"),
    
    # ä»scriptå½“å‰ä½ç½®è®¡ç®—çš„ç›¸å¯¹è·¯å¾„ï¼ˆè„šæœ¬åœ¨output/plugins/methods/æ—¶ï¼‰
    script_dir / "../../../../../src/dependencies/LightGlue-main",
    script_dir / "../../../../src/dependencies/LightGlue-main", 
    script_dir / "../../../src/dependencies/LightGlue-main",
    script_dir / "../../src/dependencies/LightGlue-main",
    
    # ä»å½“å‰å·¥ä½œç›®å½•çš„ç›¸å¯¹è·¯å¾„
    Path.cwd() / "src/dependencies/LightGlue-main",      
    Path.cwd() / "dependencies/LightGlue-main",          
    
    # å…¶ä»–å¯èƒ½çš„ä½ç½®
    script_dir / "../../../dependencies/LightGlue-main",  
    script_dir / "../../dependencies/LightGlue-main",    
]

lightglue_dir = None
for path in lightglue_search_paths:
    if (path / "lightglue" / "__init__.py").exists():
        lightglue_dir = path
        print(f"Found LightGlue at: {lightglue_dir}")
        break

if lightglue_dir is None:
    print("ERROR: LightGlue installation not found!")
    print("Please ensure LightGlue is installed at one of these locations:")
    for path in lightglue_search_paths:
        print(f"  - {path}")
    sys.exit(1)

sys.path.insert(0, str(lightglue_dir))

try:
    from lightglue import LightGlue, SuperPoint, DISK, SIFT as LightGlueSIFT, ALIKED, DoGHardNet
    from lightglue.utils import load_image, rbd
except ImportError as e:
    print(f"Error importing LightGlue modules: {e}")
    print("Please ensure LightGlue is properly installed")
    sys.exit(1)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='LightGlue Feature Matching')
    parser.add_argument('--img1', required=True, help='Path to first image')
    parser.add_argument('--img2', required=True, help='Path to second image')
    parser.add_argument('--features1', required=True, help='Path to first image features')
    parser.add_argument('--features2', required=True, help='Path to second image features')
    parser.add_argument('--output', required=True, help='Path to output matches file')
    
    # LightGlueå‚æ•°
    parser.add_argument('--feature_type', default='superpoint', 
                       choices=['superpoint', 'disk', 'sift', 'aliked', 'doghardnet'],
                       help='Feature type')
    parser.add_argument('--max_keypoints', type=int, default=2048,
                       help='Maximum number of keypoints')
    parser.add_argument('--depth_confidence', type=float, default=0.95,
                       help='Depth confidence threshold')
    parser.add_argument('--width_confidence', type=float, default=0.99,
                       help='Width confidence threshold')
    parser.add_argument('--filter_threshold', type=float, default=0.1,
                       help='Match filter threshold')
    
    # æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
    parser.add_argument('--flash_attention', action='store_true',
                       help='Enable FlashAttention')
    parser.add_argument('--mixed_precision', action='store_true',
                       help='Enable mixed precision')
    parser.add_argument('--compile_model', action='store_true',
                       help='Compile model (PyTorch 2.0+)')
    
    return parser.parse_args()


def load_features_from_file(features_path):
    """ä»æ–‡ä»¶åŠ è½½ç‰¹å¾ç‚¹å’Œæè¿°å­"""
    try:
        features = []
        descriptors = []
        
        with open(features_path, 'r') as f:
            lines = f.readlines()
            
        if not lines:
            return np.array([]), np.array([])
            
        num_features = int(lines[0].strip())
        
        for i in range(1, min(num_features + 1, len(lines))):
            parts = lines[i].strip().split()
            if len(parts) < 5:
                continue
                
            # ç‰¹å¾ç‚¹ä¿¡æ¯: x, y, size, angle, response
            x, y, size, angle, response = map(float, parts[:5])
            features.append([x, y])
            
            # æè¿°å­ä¿¡æ¯
            if len(parts) > 5:
                desc = list(map(float, parts[5:]))
                descriptors.append(desc)
        
        features = np.array(features, dtype=np.float32)
        descriptors = np.array(descriptors, dtype=np.float32) if descriptors else np.array([])
        
        print(f"Loaded {len(features)} features from {features_path}")
        return features, descriptors
        
    except Exception as e:
        print(f"Error loading features from {features_path}: {e}")
        return np.array([]), np.array([])


def perform_matching(args):
    """æ‰§è¡Œç‰¹å¾åŒ¹é…"""
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        for path in [args.img1, args.img2, args.features1, args.features2]:
            if not os.path.exists(path):
                print(f"Input file not found: {path}")
                return False
        
        # è®¾å¤‡é€‰æ‹©
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"Using device: {device}")
        
        # åŠ è½½å›¾åƒ
        image0 = load_image(args.img1).to(device)
        image1 = load_image(args.img2).to(device)
        
        print(f"Image0 shape: {image0.shape}")
        print(f"Image1 shape: {image1.shape}")
        
        # åŠ è½½å·²æœ‰ç‰¹å¾
        kpts0, desc0 = load_features_from_file(args.features1)
        kpts1, desc1 = load_features_from_file(args.features2)
        
        if len(kpts0) == 0 or len(kpts1) == 0:
            print("No features loaded from files")
            return False
            
        print(f"Loaded features0: {len(kpts0)} keypoints")
        print(f"Loaded features1: {len(kpts1)} keypoints")
        
        # è½¬æ¢ä¸ºtorchå¼ é‡
        kpts0_torch = torch.from_numpy(kpts0).float().to(device).unsqueeze(0)  # (1, N, 2)
        kpts1_torch = torch.from_numpy(kpts1).float().to(device).unsqueeze(0)  # (1, N, 2)
        
        # å¦‚æœæœ‰æè¿°å­æ•°æ®ï¼Œä½¿ç”¨å®ƒä»¬ï¼›å¦åˆ™é‡æ–°æå–
        if desc0.size > 0 and desc1.size > 0:
            print(f"Pre-computed descriptors shape: desc0={desc0.shape}, desc1={desc1.shape}")
            
            # æ£€æŸ¥æè¿°å­ç»´åº¦æ˜¯å¦ä¸ç‰¹å¾ç±»å‹åŒ¹é…
            expected_dim = 256 if args.feature_type == 'superpoint' else 128
            if desc0.shape[1] != expected_dim:
                print(f"WARNING: Descriptor dimension mismatch!")
                print(f"  Expected {expected_dim}D for {args.feature_type}, got {desc0.shape[1]}D")
                print(f"  This suggests features were extracted with a different detector")
                
                # è‡ªåŠ¨è°ƒæ•´ç‰¹å¾ç±»å‹
                if desc0.shape[1] == 128:
                    args.feature_type = 'sift'
                    print(f"  Auto-corrected feature_type to 'sift'")
                elif desc0.shape[1] == 256:
                    args.feature_type = 'superpoint' 
                    print(f"  Auto-corrected feature_type to 'superpoint'")
            
            desc0_torch = torch.from_numpy(desc0).float().to(device).unsqueeze(0)  # (1, N, D)
            desc1_torch = torch.from_numpy(desc1).float().to(device).unsqueeze(0)  # (1, N, D)
            print("Using pre-computed descriptors")
        else:
            # é‡æ–°æå–æè¿°å­
            print("Re-extracting descriptors using LightGlue extractor")
            extractor, _, _ = create_extractor_and_matcher(args)
            
            # æ„é€ ç‰¹å¾æ•°æ®ç»“æ„
            feats0 = {'keypoints': kpts0_torch, 'image_size': torch.tensor(image0.shape[-2:], device=device).unsqueeze(0)}
            feats1 = {'keypoints': kpts1_torch, 'image_size': torch.tensor(image1.shape[-2:], device=device).unsqueeze(0)}
            
            with torch.no_grad():
                # ä½¿ç”¨æå–å™¨é‡æ–°è®¡ç®—æè¿°å­
                feats0 = extractor.extract(image0, feats0)
                feats1 = extractor.extract(image1, feats1)
                desc0_torch = feats0['descriptors']
                desc1_torch = feats1['descriptors']
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥å¼ é‡ç»´åº¦
        print(f"kpts0_torch shape: {kpts0_torch.shape}")
        print(f"kpts1_torch shape: {kpts1_torch.shape}")
        print(f"desc0_torch shape: {desc0_torch.shape}")
        print(f"desc1_torch shape: {desc1_torch.shape}")
        print(f"image0 shape: {image0.shape}")
        print(f"image1 shape: {image1.shape}")
        
        # æ„é€ å®Œæ•´çš„ç‰¹å¾æ•°æ®
        feats0 = {
            'keypoints': kpts0_torch,
            'descriptors': desc0_torch,
            'image_size': torch.tensor(image0.shape[-2:], device=device).unsqueeze(0)  # ä¿®å¤ï¼šç§»é™¤é¢å¤–çš„[]
        }
        feats1 = {
            'keypoints': kpts1_torch, 
            'descriptors': desc1_torch,
            'image_size': torch.tensor(image1.shape[-2:], device=device).unsqueeze(0)  # ä¿®å¤ï¼šç§»é™¤é¢å¤–çš„[]
        }
        
        print(f"feats0 image_size: {feats0['image_size']}")
        print(f"feats1 image_size: {feats1['image_size']}")
        
        # åˆ›å»ºåŒ¹é…å™¨
        matcher_args = {
            'features': args.feature_type,
            'depth_confidence': args.depth_confidence,
            'width_confidence': args.width_confidence,
            'filter_threshold': args.filter_threshold,
        }
        
        if args.flash_attention:
            matcher_args['flash'] = True
        if args.mixed_precision:
            matcher_args['mp'] = True
            
        matcher = LightGlue(**matcher_args).eval().to(device)
        
        # ç¼–è¯‘æ¨¡å‹ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if args.compile_model and hasattr(torch, 'compile'):
            try:
                matcher = torch.compile(matcher, mode='reduce-overhead')
                print("Model compiled successfully")
            except Exception as e:
                print(f"Model compilation failed: {e}")
        
        # æ‰§è¡ŒåŒ¹é…
        with torch.no_grad():
            print("ğŸ”¥ Starting LightGlue matching...")
            print(f"   Matcher feature type: {args.feature_type}")
            print(f"   feats0 keys: {feats0.keys()}")
            print(f"   feats1 keys: {feats1.keys()}")
            
            # æœ€åä¸€æ¬¡æ£€æŸ¥ç‰¹å¾æ•°æ®æ ¼å¼
            for i, (name, feats) in enumerate([('feats0', feats0), ('feats1', feats1)]):
                print(f"   {name}:")
                for key, tensor in feats.items():
                    if isinstance(tensor, torch.Tensor):
                        print(f"     {key}: shape={tensor.shape}, dtype={tensor.dtype}")
                    else:
                        print(f"     {key}: {type(tensor)} = {tensor}")
            
            try:
                matches01 = matcher({'image0': feats0, 'image1': feats1})
                feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]
            except RuntimeError as e:
                print(f"âŒ LightGlue matching failed with RuntimeError: {e}")
                print("This might be due to:")
                print("1. Feature dimension mismatch")
                print("2. Incorrect tensor shapes")
                print("3. Model/feature type incompatibility")
                raise
            
            matches = matches01['matches']  # åŒ¹é…ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º(K, 2)
            match_confidence = matches01['matching_scores0']  # åŒ¹é…ç½®ä¿¡åº¦
            
            print(f"Found {matches.shape[0]} matches")
        
        # ä¿å­˜åŒ¹é…ç»“æœ
        save_matches(matches, match_confidence, args.output)
        return True
        
    except Exception as e:
        print(f"Error in matching: {e}")
        import traceback
        traceback.print_exc()
        return False


def create_extractor_and_matcher(args):
    """åˆ›å»ºç‰¹å¾æå–å™¨å’ŒåŒ¹é…å™¨"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    # åˆ›å»ºç‰¹å¾æå–å™¨
    extractor_args = {'max_num_keypoints': args.max_keypoints}
    
    if args.feature_type == 'superpoint':
        extractor = SuperPoint(**extractor_args).eval().to(device)
    elif args.feature_type == 'disk':
        extractor = DISK(**extractor_args).eval().to(device)  
    elif args.feature_type == 'sift':
        extractor = LightGlueSIFT(**extractor_args).eval().to(device)
    elif args.feature_type == 'aliked':
        extractor = ALIKED(**extractor_args).eval().to(device)
    elif args.feature_type == 'doghardnet':
        extractor = DoGHardNet(**extractor_args).eval().to(device)
    else:
        raise ValueError(f"Unsupported feature type: {args.feature_type}")
    
    return extractor, None, device


def save_matches(matches, confidence, output_path):
    """ä¿å­˜åŒ¹é…ç»“æœåˆ°æ–‡ä»¶"""
    try:
        with open(output_path, 'w') as f:
            for i in range(matches.shape[0]):
                if matches[i, 0] != -1 and matches[i, 1] != -1:  # æœ‰æ•ˆåŒ¹é…
                    query_idx = matches[i, 0].item()
                    train_idx = matches[i, 1].item()
                    conf = confidence[i].item() if i < len(confidence) else 1.0
                    
                    # è½¬æ¢ç½®ä¿¡åº¦ä¸ºè·ç¦»ï¼ˆè·ç¦»è¶Šå°è¶Šå¥½ï¼‰
                    distance = 1.0 - conf
                    
                    f.write(f"{query_idx} {train_idx} {distance:.6f}\n")
        
        print(f"Matches saved to {output_path}")
        
    except Exception as e:
        print(f"Error saving matches: {e}")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("LightGlue Feature Matching Started")
    print(f"Feature type: {args.feature_type}")
    print(f"Max keypoints: {args.max_keypoints}")
    print(f"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    
    # æ‰§è¡ŒåŒ¹é…
    if perform_matching(args):
        print("Feature matching completed successfully")
        return 0
    else:
        print("Feature matching failed")
        return 1


if __name__ == '__main__':
    sys.exit(main())
