/**
 * @file converter_opencv.cpp
 * @brief OpenCV data type converter implementation | OpenCVæ•°æ®ç±»å‹è½¬æ¢å™¨å®ç°
 * @details High-performance conversion implementation with SIMD-friendly batch operations
 *          é«˜æ€§èƒ½è½¬æ¢å®ç°ï¼Œæ”¯æŒSIMDå‹å¥½çš„æ‰¹é‡æ“ä½œ
 * @copyright Copyright (c) 2024 Qi Cai
 * Licensed under the Mozilla Public License Version 2.0
 */

#include "converter_opencv.hpp"
#include <po_core/types.hpp>
#include <algorithm>

namespace PoSDK
{
    namespace Converter
    {
        using namespace PoSDK::types;

        // ==================================================================================
        // Descriptor Type Parsing | æè¿°å­ç±»å‹è§£æ
        // ==================================================================================

        OpenCVConverter::DescriptorType OpenCVConverter::ParseDescriptorType(const std::string &detector_type)
        {
            // SIFT and SURF use FLOAT32 descriptors | SIFTå’ŒSURFä½¿ç”¨FLOAT32æè¿°å­
            if (detector_type == "SIFT" || detector_type == "SURF")
            {
                return DescriptorType::FLOAT32;
            }
            // BRISK, ORB, AKAZE use UINT8 descriptors | BRISKã€ORBã€AKAZEä½¿ç”¨UINT8æè¿°å­
            else if (detector_type == "BRISK" || detector_type == "ORB" || detector_type == "AKAZE")
            {
                return DescriptorType::UINT8;
            }
            // Default to FLOAT32 | é»˜è®¤ä½¿ç”¨FLOAT32
            return DescriptorType::FLOAT32;
        }

        // ==================================================================================
        // Level 1: FeaturePoints â†” std::vector<cv::KeyPoint> (SOA Batch Conversion)
        //          FeaturePoints â†” std::vector<cv::KeyPoint> (SOAæ‰¹é‡è½¬æ¢)
        // ==================================================================================

        bool OpenCVConverter::CVKeyPoints2FeaturePoints(
            const std::vector<cv::KeyPoint> &keypoints,
            FeaturePoints &feature_points)
        {
            try
            {
                const size_t num_features = keypoints.size();
                if (num_features == 0)
                {
                    LOG_DEBUG_ZH << "[OpenCVConverter] è­¦å‘Š: è¾“å…¥å…³é”®ç‚¹ä¸ºç©º";
                    LOG_DEBUG_EN << "[OpenCVConverter] Warning: Input keypoints are empty";
                    return true;
                }

                // ğŸš€ Batch allocate SOA storage (SIMD-friendly contiguous memory)
                // ğŸš€ æ‰¹é‡åˆ†é…SOAå­˜å‚¨ï¼ˆSIMDå‹å¥½çš„è¿ç»­å†…å­˜ï¼‰
                feature_points.resize(num_features);

                // ğŸš€ Batch write using SOA accessors (compiler can vectorize)
                // ğŸš€ ä½¿ç”¨SOAè®¿é—®å™¨æ‰¹é‡å†™å…¥ï¼ˆç¼–è¯‘å™¨å¯ä»¥å‘é‡åŒ–ï¼‰
                auto &coords = feature_points.GetCoordsRef(); // 2Ã—N Eigen matrix | 2Ã—N EigençŸ©é˜µ
                auto &sizes = feature_points.GetSizesRef();   // vector<float>
                auto &angles = feature_points.GetAnglesRef(); // vector<float>

                // Batch conversion loop (SIMD-optimizable) | æ‰¹é‡è½¬æ¢å¾ªç¯ï¼ˆå¯SIMDä¼˜åŒ–ï¼‰
                for (size_t i = 0; i < num_features; ++i)
                {
                    coords(0, i) = static_cast<double>(keypoints[i].pt.x);
                    coords(1, i) = static_cast<double>(keypoints[i].pt.y);
                    sizes[i] = keypoints[i].size;
                    angles[i] = keypoints[i].angle;
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVKeyPoints2FeaturePointsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVKeyPoints2FeaturePoints: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::FeaturePoints2CVKeyPoints(
            const FeaturePoints &feature_points,
            std::vector<cv::KeyPoint> &keypoints)
        {
            try
            {
                const size_t num_features = feature_points.size();

                if (num_features == 0)
                {
                    keypoints.clear();
                    return true;
                }

                // ğŸš€ Batch allocate all cv::KeyPoint objects at once (reduces memory allocations)
                // ğŸš€ æ‰¹é‡åˆ†é…æ‰€æœ‰cv::KeyPointå¯¹è±¡ï¼ˆå‡å°‘å†…å­˜åˆ†é…æ¬¡æ•°ï¼‰
                keypoints.resize(num_features);

                // ğŸš€ Zero-copy batch read using SOA accessors (SIMD-friendly)
                // ğŸš€ ä½¿ç”¨SOAè®¿é—®å™¨é›¶æ‹·è´æ‰¹é‡è¯»å–ï¼ˆSIMDå‹å¥½ï¼‰
                const auto &coords = feature_points.GetCoordsRef(); // 2Ã—N Eigen matrix | 2Ã—N EigençŸ©é˜µ
                const auto &sizes = feature_points.GetSizesRef();   // const vector<float>&
                const auto &angles = feature_points.GetAnglesRef(); // const vector<float>&

                // ğŸš€ Direct write to pre-allocated memory (better cache locality, compiler can vectorize)
                // ğŸš€ ç›´æ¥å†™å…¥é¢„åˆ†é…å†…å­˜ï¼ˆæ›´å¥½çš„ç¼“å­˜å±€éƒ¨æ€§ï¼Œç¼–è¯‘å™¨å¯ä»¥å‘é‡åŒ–ï¼‰
                for (size_t i = 0; i < num_features; ++i)
                {
                    keypoints[i].pt.x = static_cast<float>(coords(0, i));
                    keypoints[i].pt.y = static_cast<float>(coords(1, i));
                    keypoints[i].size = sizes[i];
                    keypoints[i].angle = angles[i];
                    // Set default values for other fields | è®¾ç½®å…¶ä»–å­—æ®µçš„é»˜è®¤å€¼
                    keypoints[i].response = 0.0f;
                    keypoints[i].octave = 0;
                    keypoints[i].class_id = -1;
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] FeaturePoints2CVKeyPointsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in FeaturePoints2CVKeyPoints: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::CVDescriptors2Descriptors(
            const cv::Mat &descriptors_cv,
            Descriptors &descriptors_out,
            const std::string &detector_type)
        {
            try
            {
                if (descriptors_cv.empty())
                {
                    descriptors_out.clear();
                    return true;
                }

                const DescriptorType desc_type = ParseDescriptorType(detector_type);
                const size_t num_features = descriptors_cv.rows;
                const size_t descriptor_dim = descriptors_cv.cols;

                // ğŸš€ Batch allocate all memory at once (single allocation) | ä¸€æ¬¡æ€§æ‰¹é‡åˆ†é…æ‰€æœ‰å†…å­˜ï¼ˆå•æ¬¡åˆ†é…ï¼‰
                descriptors_out.resize(num_features, descriptor_dim);

                if (desc_type == DescriptorType::UINT8)
                {
                    // UINT8 â†’ FLOAT32 conversion with SIMD optimization | UINT8 â†’ FLOAT32è½¬æ¢ï¼Œä½¿ç”¨SIMDä¼˜åŒ–
#if defined(POSDK_SIMD_ENABLED)
                    for (size_t i = 0; i < num_features; ++i)
                    {
                        const uint8_t *src = descriptors_cv.ptr<uint8_t>(i);
                        float *dest = descriptors_out[i];

                        size_t j = 0;
                        const size_t simd_end = descriptor_dim - (descriptor_dim % 8);

                        // AVX2: convert 8 uint8_t to 8 floats at a time | AVX2ï¼šä¸€æ¬¡å°†8ä¸ªuint8_tè½¬æ¢ä¸º8ä¸ªfloat
                        for (; j < simd_end; j += 8)
                        {
                            // Load 8 uint8_t values | åŠ è½½8ä¸ªuint8_tå€¼
                            __m128i u8_vals = _mm_loadl_epi64(reinterpret_cast<const __m128i *>(src + j));
                            // Convert to int32 | è½¬æ¢ä¸ºint32
                            __m256i i32_vals = _mm256_cvtepu8_epi32(u8_vals);
                            // Convert to float | è½¬æ¢ä¸ºfloat
                            __m256 f32_vals = _mm256_cvtepi32_ps(i32_vals);
                            // Store result | å­˜å‚¨ç»“æœ
                            _mm256_storeu_ps(dest + j, f32_vals);
                        }

                        // Handle remaining elements | å¤„ç†å‰©ä½™å…ƒç´ 
                        for (; j < descriptor_dim; ++j)
                        {
                            dest[j] = static_cast<float>(src[j]);
                        }
                    }
#else
                    // Fallback: element-wise conversion | å›é€€ï¼šé€å…ƒç´ è½¬æ¢
                    for (size_t i = 0; i < num_features; ++i)
                    {
                        const uint8_t *src = descriptors_cv.ptr<uint8_t>(i);
                        float *dest = descriptors_out[i];
                        for (size_t j = 0; j < descriptor_dim; ++j)
                        {
                            dest[j] = static_cast<float>(src[j]);
                        }
                    }
#endif
                }
                else
                {
                    // ğŸš€ FLOAT32 â†’ FLOAT32: Single memcpy (zero-copy optimization) | FLOAT32 â†’ FLOAT32ï¼šå•æ¬¡memcpyï¼ˆé›¶æ‹·è´ä¼˜åŒ–ï¼‰
                    if (descriptors_cv.isContinuous())
                    {
                        // Best case: cv::Mat is contiguous, single memcpy for entire buffer | æœ€ä½³æƒ…å†µï¼šcv::Matè¿ç»­ï¼Œæ•´ä¸ªç¼“å†²åŒºå•æ¬¡memcpy
                        std::memcpy(descriptors_out.data(), descriptors_cv.ptr<float>(0), num_features * descriptor_dim * sizeof(float));
                    }
                    else
                    {
                        // Row-by-row memcpy | é€è¡Œmemcpy
                        for (size_t i = 0; i < num_features; ++i)
                        {
                            const float *src = descriptors_cv.ptr<float>(i);
                            float *dest = descriptors_out[i];
                            std::memcpy(dest, src, descriptor_dim * sizeof(float));
                        }
                    }
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVDescriptors2Descriptorsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVDescriptors2Descriptors: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::Descriptors2CVDescriptors(
            const Descriptors &descriptors,
            cv::Mat &descriptors_cv_out,
            const std::string &detector_type)
        {
            try
            {
                if (descriptors.empty())
                {
                    descriptors_cv_out.release();
                    return true;
                }

                const DescriptorType desc_type = ParseDescriptorType(detector_type);
                const size_t num_features = descriptors.size();
                const size_t descriptor_dim = descriptors.dim();

                if (desc_type == DescriptorType::UINT8)
                {
                    // FLOAT32 â†’ UINT8 conversion with SIMD optimization | FLOAT32 â†’ UINT8è½¬æ¢ï¼Œä½¿ç”¨SIMDä¼˜åŒ–
                    descriptors_cv_out.create(num_features, descriptor_dim, CV_8U);

#if defined(POSDK_SIMD_ENABLED)
                    for (size_t i = 0; i < num_features; ++i)
                    {
                        const float *src = descriptors[i];
                        uint8_t *dest = descriptors_cv_out.ptr<uint8_t>(i);

                        size_t j = 0;
                        const size_t simd_end = descriptor_dim - (descriptor_dim % 8);

                        // AVX2: convert 8 floats to 8 uint8_t at a time | AVX2ï¼šä¸€æ¬¡å°†8ä¸ªfloatè½¬æ¢ä¸º8ä¸ªuint8_t
                        for (; j < simd_end; j += 8)
                        {
                            // Load 8 floats | åŠ è½½8ä¸ªfloat
                            __m256 f32_vals = _mm256_loadu_ps(src + j);
                            // Convert to int32 | è½¬æ¢ä¸ºint32
                            __m256i i32_vals = _mm256_cvtps_epi32(f32_vals);
                            // Pack int32 to int16 | å°†int32æ‰“åŒ…ä¸ºint16
                            __m128i i16_vals = _mm_packs_epi32(_mm256_castsi256_si128(i32_vals),
                                                               _mm256_extracti128_si256(i32_vals, 1));
                            // Pack int16 to uint8 | å°†int16æ‰“åŒ…ä¸ºuint8
                            __m128i u8_vals = _mm_packus_epi16(i16_vals, _mm_setzero_si128());
                            // Store result | å­˜å‚¨ç»“æœ
                            _mm_storel_epi64(reinterpret_cast<__m128i *>(dest + j), u8_vals);
                        }

                        // Handle remaining elements | å¤„ç†å‰©ä½™å…ƒç´ 
                        for (; j < descriptor_dim; ++j)
                        {
                            dest[j] = static_cast<uint8_t>(src[j]);
                        }
                    }
#else
                    // Fallback: element-wise conversion | å›é€€ï¼šé€å…ƒç´ è½¬æ¢
                    for (size_t i = 0; i < num_features; ++i)
                    {
                        const float *src = descriptors[i];
                        uint8_t *dest = descriptors_cv_out.ptr<uint8_t>(i);
                        for (size_t j = 0; j < descriptor_dim; ++j)
                        {
                            dest[j] = static_cast<uint8_t>(src[j]);
                        }
                    }
#endif
                }
                else
                {
                    // ğŸš€ FLOAT32 â†’ FLOAT32: Single memcpy (zero-copy optimization) | FLOAT32 â†’ FLOAT32ï¼šå•æ¬¡memcpyï¼ˆé›¶æ‹·è´ä¼˜åŒ–ï¼‰
                    descriptors_cv_out.create(num_features, descriptor_dim, CV_32F);

                    if (descriptors_cv_out.isContinuous())
                    {
                        // Best case: single memcpy for entire buffer | æœ€ä½³æƒ…å†µï¼šæ•´ä¸ªç¼“å†²åŒºå•æ¬¡memcpy
                        std::memcpy(descriptors_cv_out.ptr<float>(0), descriptors.data(), num_features * descriptor_dim * sizeof(float));
                    }
                    else
                    {
                        // Row-by-row memcpy | é€è¡Œmemcpy
                        for (size_t i = 0; i < num_features; ++i)
                        {
                            const float *src = descriptors[i];
                            float *dest = descriptors_cv_out.ptr<float>(i);
                            std::memcpy(dest, src, descriptor_dim * sizeof(float));
                        }
                    }
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] Descriptors2CVDescriptorsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in Descriptors2CVDescriptors: " << e.what();
                return false;
            }
        }

        // ==================================================================================
        // Level 2: ImageFeatureInfo â†” CV Features (Single Image Conversion)
        //          ImageFeatureInfo â†” CV Features (å•å›¾åƒè½¬æ¢)
        // ==================================================================================

        bool OpenCVConverter::CVFeatures2ImageFeatureInfo(
            const std::vector<cv::KeyPoint> &keypoints,
            ImageFeatureInfo &image_features,
            const std::string &image_path)
        {
            try
            {
                image_features = ImageFeatureInfo(image_path);
                FeaturePoints &feature_points = image_features.GetFeaturePoints();

                // Use Level 1 batch converter | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨
                return CVKeyPoints2FeaturePoints(keypoints, feature_points);
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVFeatures2ImageFeatureInfoè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVFeatures2ImageFeatureInfo: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::CVFeatures2ImageFeatureInfoWithDesc(
            const std::vector<cv::KeyPoint> &keypoints,
            const cv::Mat &descriptors_cv,
            ImageFeatureInfo &image_features,
            Descriptors &descriptors_out,
            const std::string &image_path,
            const std::string &detector_type)
        {
            try
            {
                // Convert features using Level 1 batch converter | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨è½¬æ¢ç‰¹å¾
                if (!CVFeatures2ImageFeatureInfo(keypoints, image_features, image_path))
                {
                    return false;
                }

                // Convert descriptors using Level 1 batch converter | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨è½¬æ¢æè¿°å­
                return CVDescriptors2Descriptors(descriptors_cv, descriptors_out, detector_type);
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVFeatures2ImageFeatureInfoWithDescè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVFeatures2ImageFeatureInfoWithDesc: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::ImageFeatureInfo2CVFeatures(
            const ImageFeatureInfo &image_features,
            std::vector<cv::KeyPoint> &keypoints)
        {
            try
            {
                const FeaturePoints &feature_points = image_features.GetFeaturePoints();

                // Use Level 1 batch converter with zero-copy SOA access | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨å’Œé›¶æ‹·è´SOAè®¿é—®
                return FeaturePoints2CVKeyPoints(feature_points, keypoints);
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] ImageFeatureInfo2CVFeaturesè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in ImageFeatureInfo2CVFeatures: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::ImageFeatureInfo2CVFeaturesWithDesc(
            const ImageFeatureInfo &image_features,
            const Descriptors &descriptors,
            std::vector<cv::KeyPoint> &keypoints,
            cv::Mat &descriptors_out,
            const std::string &detector_type)
        {
            try
            {
                const size_t num_features = image_features.GetNumFeatures();

                // Handle descriptor count mismatch gracefully | ä¼˜é›…å¤„ç†æè¿°å­æ•°é‡ä¸åŒ¹é…
                if (descriptors.size() != num_features)
                {
                    LOG_DEBUG_ZH << "[OpenCVConverter] è­¦å‘Š: æè¿°å­æ•°é‡ (" << descriptors.size()
                                 << ") ä¸ç‰¹å¾ç‚¹æ•°é‡ (" << num_features << ") ä¸åŒ¹é…ï¼Œä»…è½¬æ¢å…³é”®ç‚¹";
                    LOG_DEBUG_EN << "[OpenCVConverter] Warning: Descriptor count (" << descriptors.size()
                                 << ") does not match feature count (" << num_features << "), converting keypoints only";
                    descriptors_out.release();
                    return ImageFeatureInfo2CVFeatures(image_features, keypoints);
                }

                // Convert features using Level 1 batch converter | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨è½¬æ¢ç‰¹å¾
                if (!ImageFeatureInfo2CVFeatures(image_features, keypoints))
                {
                    return false;
                }

                // Convert descriptors using Level 1 batch converter | ä½¿ç”¨Level 1æ‰¹é‡è½¬æ¢å™¨è½¬æ¢æè¿°å­
                return Descriptors2CVDescriptors(descriptors, descriptors_out, detector_type);
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] ImageFeatureInfo2CVFeaturesWithDescè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in ImageFeatureInfo2CVFeaturesWithDesc: " << e.what();
                return false;
            }
        }

        // ==================================================================================
        // Level 3: FeaturesInfo â†” CV Features (Multiple Images Batch Conversion)
        //          FeaturesInfo â†” CV Features (å¤šå›¾åƒæ‰¹é‡è½¬æ¢)
        // ==================================================================================

        bool OpenCVConverter::CVFeatures2FeaturesInfo(
            const std::vector<cv::KeyPoint> &keypoints,
            FeaturesInfoPtr &features_info_ptr,
            const std::string &image_path)
        {
            try
            {
                if (!features_info_ptr)
                {
                    features_info_ptr = std::make_shared<FeaturesInfo>();
                }

                ImageFeatureInfo image_features;
                if (!CVFeatures2ImageFeatureInfo(keypoints, image_features, image_path))
                {
                    return false;
                }

                features_info_ptr->push_back(std::move(image_features));
                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVFeatures2FeaturesInfoè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVFeatures2FeaturesInfo: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::CVFeatures2FeaturesInfoWithDesc(
            const std::vector<cv::KeyPoint> &keypoints,
            const cv::Mat &descriptors,
            FeaturesInfoPtr &features_info_ptr,
            Descriptors &descriptors_out,
            const std::string &image_path,
            const std::string &detector_type)
        {
            try
            {
                if (!features_info_ptr)
                {
                    features_info_ptr = std::make_shared<FeaturesInfo>();
                }

                ImageFeatureInfo image_features;
                if (!CVFeatures2ImageFeatureInfoWithDesc(keypoints, descriptors, image_features,
                                                         descriptors_out, image_path, detector_type))
                {
                    return false;
                }

                features_info_ptr->push_back(std::move(image_features));
                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVFeatures2FeaturesInfoWithDescè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVFeatures2FeaturesInfoWithDesc: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::FeaturesInfo2CVFeatures(
            const ImageFeatureInfo &image_features,
            std::vector<cv::KeyPoint> &keypoints)
        {
            // Alias for ImageFeatureInfo2CVFeatures | ImageFeatureInfo2CVFeaturesçš„åˆ«å
            return ImageFeatureInfo2CVFeatures(image_features, keypoints);
        }

        bool OpenCVConverter::FeaturesInfo2CVFeaturesWithDesc(
            const ImageFeatureInfo &image_features,
            const Descriptors &descriptors,
            std::vector<cv::KeyPoint> &keypoints,
            cv::Mat &descriptors_out,
            const std::string &detector_type)
        {
            // Alias for ImageFeatureInfo2CVFeaturesWithDesc | ImageFeatureInfo2CVFeaturesWithDescçš„åˆ«å
            return ImageFeatureInfo2CVFeaturesWithDesc(image_features, descriptors, keypoints,
                                                       descriptors_out, detector_type);
        }

        // ==================================================================================
        // Match Conversion Functions | åŒ¹é…è½¬æ¢å‡½æ•°
        // ==================================================================================

        void OpenCVConverter::CVDMatch2IdMatch(const cv::DMatch &cv_match, IdMatch &match)
        {
            match.i = cv_match.queryIdx;
            match.j = cv_match.trainIdx;
            match.is_inlier = false; // Default to false | é»˜è®¤ä¸ºfalse
        }

        bool OpenCVConverter::CVDMatch2IdMatches(const std::vector<cv::DMatch> &cv_matches,
                                                 IdMatches &matches)
        {
            try
            {
                matches.clear();
                matches.reserve(cv_matches.size());

                for (const auto &cv_match : cv_matches)
                {
                    IdMatch match;
                    CVDMatch2IdMatch(cv_match, match);
                    matches.push_back(match);
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVDMatch2IdMatchesè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVDMatch2IdMatches: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::CVDMatch2Matches(const std::vector<cv::DMatch> &cv_matches,
                                               const IndexT view_id1,
                                               const IndexT view_id2,
                                               MatchesPtr &matches_ptr)
        {
            try
            {
                if (!matches_ptr)
                {
                    matches_ptr = std::make_shared<Matches>();
                }

                IdMatches id_matches;
                if (!CVDMatch2IdMatches(cv_matches, id_matches))
                {
                    return false;
                }

                ViewPair view_pair(view_id1, view_id2);
                (*matches_ptr)[view_pair] = std::move(id_matches);

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVDMatch2Matchesè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVDMatch2Matches: " << e.what();
                return false;
            }
        }

        void OpenCVConverter::IdMatch2CVDMatch(const IdMatch &match, cv::DMatch &cv_match)
        {
            cv_match.queryIdx = match.i;
            cv_match.trainIdx = match.j;
            cv_match.distance = 0.0f; // Not used in PoSDK | PoSDKä¸­ä¸ä½¿ç”¨
        }

        bool OpenCVConverter::IdMatches2CVPoints(
            const IdMatches &matches,
            const FeaturesInfo &features_info,
            const CameraModels &camera_models,
            const ViewPair &view_pair,
            std::vector<cv::Point2f> &points1,
            std::vector<cv::Point2f> &points2)
        {
            try
            {
                points1.clear();
                points2.clear();
                points1.reserve(matches.size());
                points2.reserve(matches.size());

                // Check if feature information exists | æ£€æŸ¥ç‰¹å¾ä¿¡æ¯æ˜¯å¦å­˜åœ¨
                if (features_info.size() <= std::max(view_pair.first, view_pair.second))
                {
                    LOG_ERROR_ZH << "[OpenCVConverter] ç‰¹å¾ä¿¡æ¯å¤§å° (" << features_info.size()
                                 << ") å¯¹è§†å›¾å¯¹ (" << view_pair.first << ", " << view_pair.second << ") ä¸è¶³";
                    LOG_ERROR_EN << "[OpenCVConverter] Features info size (" << features_info.size()
                                 << ") insufficient for view pair (" << view_pair.first
                                 << ", " << view_pair.second << ")";
                    return false;
                }

                // Access ImageFeatureInfo using array indexing | ä½¿ç”¨æ•°ç»„ç´¢å¼•è®¿é—®ImageFeatureInfo
                const ImageFeatureInfo *features1 = &features_info.at(view_pair.first);
                const ImageFeatureInfo *features2 = &features_info.at(view_pair.second);

                if (!features1 || !features2)
                {
                    LOG_ERROR_ZH << "[OpenCVConverter] ç‰¹å¾ä¿¡æ¯æŒ‡é’ˆä¸ºç©º";
                    LOG_ERROR_EN << "[OpenCVConverter] Features info pointer is null";
                    return false;
                }

                const auto &feature_points1 = features1->GetFeaturePoints();
                const auto &feature_points2 = features2->GetFeaturePoints();

                for (const auto &match : matches)
                {
                    // Check index validity | æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
                    if (match.i >= feature_points1.size() || match.j >= feature_points2.size())
                    {
                        LOG_DEBUG_ZH << "[OpenCVConverter] è­¦å‘Š: åŒ¹é…ä¸­ç‰¹å¾ç´¢å¼•æ— æ•ˆ: (" << match.i << ", " << match.j << ")";
                        LOG_DEBUG_EN << "[OpenCVConverter] Warning: Invalid feature index in match: ("
                                     << match.i << ", " << match.j << ")";
                        continue;
                    }

                    // Get feature point coordinates | è·å–ç‰¹å¾ç‚¹åæ ‡
                    const Feature f1_coord = feature_points1.GetCoord(match.i);
                    const Feature f2_coord = feature_points2.GetCoord(match.j);

                    points1.emplace_back(static_cast<float>(f1_coord.x()), static_cast<float>(f1_coord.y()));
                    points2.emplace_back(static_cast<float>(f2_coord.x()), static_cast<float>(f2_coord.y()));
                }

                if (points1.size() != matches.size())
                {
                    LOG_DEBUG_ZH << "[OpenCVConverter] è­¦å‘Š: ç”±äºæ— æ•ˆç´¢å¼•ï¼Œéƒ¨åˆ†åŒ¹é…è¢«è·³è¿‡ã€‚åŸå§‹: "
                                 << matches.size() << ", æœ‰æ•ˆ: " << points1.size();
                    LOG_DEBUG_EN << "[OpenCVConverter] Warning: Some matches were skipped due to invalid indices. "
                                 << "Original: " << matches.size() << ", Valid: " << points1.size();
                }

                return !points1.empty();
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] IdMatches2CVPointsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in IdMatches2CVPoints: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::MatchesDataPtr2CVPoints(
            const DataPtr &matches_data_ptr,
            const FeaturesInfo &features_info,
            const CameraModels &camera_models,
            const ViewPair &view_pair,
            std::vector<cv::Point2f> &points1,
            std::vector<cv::Point2f> &points2)
        {
            try
            {
                points1.clear();
                points2.clear();

                // Get match data from DataPtr | ä»DataPtrè·å–åŒ¹é…æ•°æ®
                void *raw_data = matches_data_ptr->GetData();
                if (!raw_data)
                {
                    LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: matches_data_ptr->GetData() è¿”å›ç©ºæŒ‡é’ˆ";
                    LOG_ERROR_EN << "[OpenCVConverter] Error: matches_data_ptr->GetData() returned null";
                    return false;
                }

                // Convert raw pointer to IdMatches type | å°†åŸå§‹æŒ‡é’ˆè½¬æ¢ä¸ºIdMatchesç±»å‹
                const IdMatches *matches_ptr = static_cast<const IdMatches *>(raw_data);
                if (!matches_ptr)
                {
                    LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: è½¬æ¢ä¸ºIdMatches*å¤±è´¥";
                    LOG_ERROR_EN << "[OpenCVConverter] Error: Failed to cast to IdMatches*";
                    return false;
                }

                return IdMatches2CVPoints(*matches_ptr, features_info, camera_models, view_pair, points1, points2);
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] MatchesDataPtr2CVPointsè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in MatchesDataPtr2CVPoints: " << e.what();
                return false;
            }
        }

        // ==================================================================================
        // Camera Model Conversion Functions | ç›¸æœºæ¨¡å‹è½¬æ¢å‡½æ•°
        // ==================================================================================

        bool OpenCVConverter::CVCalibration2CameraModel(const cv::Mat &camera_matrix,
                                                        const cv::Mat &dist_coeffs,
                                                        const cv::Size &image_size,
                                                        CameraModel &camera_model,
                                                        DistortionType distortion_type)
        {
            try
            {
                // Extract camera intrinsics from OpenCV matrix | ä»OpenCVçŸ©é˜µæå–ç›¸æœºå†…å‚
                double fx = camera_matrix.at<double>(0, 0);
                double fy = camera_matrix.at<double>(1, 1);
                double cx = camera_matrix.at<double>(0, 2);
                double cy = camera_matrix.at<double>(1, 2);

                // Set basic camera intrinsics | è®¾ç½®åŸºæœ¬ç›¸æœºå†…å‚
                camera_model.SetCameraIntrinsics(fx, fy, cx, cy, image_size.width, image_size.height);

                // Process distortion coefficients | å¤„ç†ç•¸å˜ç³»æ•°
                if (dist_coeffs.empty() || distortion_type == DistortionType::NO_DISTORTION)
                {
                    camera_model.SetDistortionParams(DistortionType::NO_DISTORTION, {}, {});
                    return true;
                }

                std::vector<double> radial_distortion;
                std::vector<double> tangential_distortion;

                // Parse distortion coefficients based on type | æ ¹æ®ç±»å‹è§£æç•¸å˜ç³»æ•°
                switch (distortion_type)
                {
                case DistortionType::RADIAL_K1:
                    if (dist_coeffs.total() >= 1)
                    {
                        radial_distortion = {dist_coeffs.at<double>(0)}; // k1
                    }
                    break;

                case DistortionType::RADIAL_K3:
                    if (dist_coeffs.total() >= 5)
                    {
                        radial_distortion = {
                            dist_coeffs.at<double>(0), // k1
                            dist_coeffs.at<double>(1), // k2
                            dist_coeffs.at<double>(4)  // k3
                        };
                    }
                    break;

                case DistortionType::BROWN_CONRADY:
                    if (dist_coeffs.total() >= 5)
                    {
                        radial_distortion = {
                            dist_coeffs.at<double>(0), // k1
                            dist_coeffs.at<double>(1), // k2
                            dist_coeffs.at<double>(4)  // k3
                        };
                        tangential_distortion = {
                            dist_coeffs.at<double>(2), // p1
                            dist_coeffs.at<double>(3)  // p2
                        };
                    }
                    break;

                default:
                    LOG_ERROR_ZH << "[OpenCVConverter] ä¸æ”¯æŒçš„ç•¸å˜ç±»å‹";
                    LOG_ERROR_EN << "[OpenCVConverter] Unsupported distortion type";
                    return false;
                }

                camera_model.SetDistortionParams(distortion_type, radial_distortion, tangential_distortion);
                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CVCalibration2CameraModelè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CVCalibration2CameraModel: " << e.what();
                return false;
            }
        }

        bool OpenCVConverter::CameraModel2CVCalibration(const CameraModel &camera_model,
                                                        cv::Mat &camera_matrix,
                                                        cv::Mat &dist_coeffs)
        {
            try
            {
                // Get camera intrinsics | è·å–ç›¸æœºå†…å‚
                const auto &intrinsics = camera_model.GetIntrinsics();

                // Create OpenCV camera matrix | åˆ›å»ºOpenCVç›¸æœºçŸ©é˜µ
                camera_matrix = cv::Mat::eye(3, 3, CV_64F);
                camera_matrix.at<double>(0, 0) = intrinsics.GetFx();
                camera_matrix.at<double>(1, 1) = intrinsics.GetFy();
                camera_matrix.at<double>(0, 2) = intrinsics.GetCx();
                camera_matrix.at<double>(1, 2) = intrinsics.GetCy();

                // Create distortion coefficient matrix based on model type | æ ¹æ®ç•¸å˜æ¨¡å‹ç±»å‹åˆ›å»ºç•¸å˜ç³»æ•°
                switch (intrinsics.GetDistortionType())
                {
                case DistortionType::NO_DISTORTION:
                    dist_coeffs = cv::Mat(); // Empty matrix for no distortion | ç©ºçŸ©é˜µè¡¨ç¤ºæ— ç•¸å˜
                    break;

                case DistortionType::RADIAL_K1:
                    if (intrinsics.GetRadialDistortion().size() != 1)
                    {
                        LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: K1æ¨¡å‹çš„å¾„å‘ç•¸å˜å‚æ•°æ•°é‡æ— æ•ˆ";
                        LOG_ERROR_EN << "[OpenCVConverter] Error: Invalid number of radial distortion parameters for K1 model";
                        return false;
                    }
                    dist_coeffs = cv::Mat::zeros(1, 5, CV_64F);
                    dist_coeffs.at<double>(0) = intrinsics.GetRadialDistortion()[0]; // k1
                    break;

                case DistortionType::RADIAL_K3:
                    if (intrinsics.GetRadialDistortion().size() != 3)
                    {
                        LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: K3æ¨¡å‹çš„å¾„å‘ç•¸å˜å‚æ•°æ•°é‡æ— æ•ˆ";
                        LOG_ERROR_EN << "[OpenCVConverter] Error: Invalid number of radial distortion parameters for K3 model";
                        return false;
                    }
                    dist_coeffs = cv::Mat::zeros(1, 5, CV_64F);
                    dist_coeffs.at<double>(0) = intrinsics.GetRadialDistortion()[0]; // k1
                    dist_coeffs.at<double>(1) = intrinsics.GetRadialDistortion()[1]; // k2
                    dist_coeffs.at<double>(4) = intrinsics.GetRadialDistortion()[2]; // k3
                    break;

                case DistortionType::BROWN_CONRADY:
                    if (intrinsics.GetRadialDistortion().size() != 3 ||
                        intrinsics.GetTangentialDistortion().size() != 2)
                    {
                        LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: Brown-Conradyæ¨¡å‹çš„ç•¸å˜å‚æ•°æ•°é‡æ— æ•ˆ";
                        LOG_ERROR_EN << "[OpenCVConverter] Error: Invalid number of distortion parameters for Brown-Conrady model";
                        return false;
                    }
                    dist_coeffs = cv::Mat::zeros(1, 5, CV_64F);
                    dist_coeffs.at<double>(0) = intrinsics.GetRadialDistortion()[0];     // k1
                    dist_coeffs.at<double>(1) = intrinsics.GetRadialDistortion()[1];     // k2
                    dist_coeffs.at<double>(2) = intrinsics.GetTangentialDistortion()[0]; // p1
                    dist_coeffs.at<double>(3) = intrinsics.GetTangentialDistortion()[1]; // p2
                    dist_coeffs.at<double>(4) = intrinsics.GetRadialDistortion()[2];     // k3
                    break;

                default:
                    LOG_ERROR_ZH << "[OpenCVConverter] é”™è¯¯: ä¸æ”¯æŒçš„ç•¸å˜ç±»å‹";
                    LOG_ERROR_EN << "[OpenCVConverter] Error: Unsupported distortion type";
                    return false;
                }

                return true;
            }
            catch (const std::exception &e)
            {
                LOG_ERROR_ZH << "[OpenCVConverter] CameraModel2CVCalibrationè½¬æ¢å¤±è´¥: " << e.what();
                LOG_ERROR_EN << "[OpenCVConverter] Error in CameraModel2CVCalibration: " << e.what();
                return false;
            }
        }

        // ==================================================================================
        // Internal Helper Functions | å†…éƒ¨è¾…åŠ©å‡½æ•°
        // ==================================================================================

        void OpenCVConverter::CVKeyPoint2Feature(
            const cv::KeyPoint &kp,
            Feature &coord,
            float &size,
            float &angle)
        {
            coord = Feature(kp.pt.x, kp.pt.y);
            size = kp.size;
            angle = kp.angle;
        }

        void OpenCVConverter::Feature2CVKeyPoint(
            const FeaturePoints &feature_points,
            size_t feature_index,
            cv::KeyPoint &kp)
        {
            const Feature coord = feature_points.GetCoord(feature_index);
            kp.pt.x = static_cast<float>(coord.x());
            kp.pt.y = static_cast<float>(coord.y());
            kp.size = feature_points.GetSize(feature_index);
            kp.angle = feature_points.GetAngle(feature_index);
        }

    } // namespace Converter
} // namespace PoSDK
